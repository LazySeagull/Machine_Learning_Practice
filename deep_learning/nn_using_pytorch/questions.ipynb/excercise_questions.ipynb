{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "072d59a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how is pytorch tensor different to numpy array and how is pytorch different from numpy since they are similar in many ways "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba083675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFirstly tensor and matrix are very different. Matrix is basically a subset of tensor cuz matrix is 2d while tenors in maths can be \\n1d ( scaler) , 2d , 3d , ... , nd. \\n\\nnow for pytorch tensor , it acts like a numpy array but is very different.\\nfirstly we can store it on gpu which we cant do with numpy array \\nnext they have .grad() property which we can use to calculate their graidents \\nthey store compuation graph for the operations performed on the tenosr if we want to stop it \\nfrom storing computation graph say when maybe we want to validate our model and we dont want the validation calculatioin \\nto hamper the model training computation graph , we can use with torch.no_grad() property. Moreover using \\n.backward() method allows us to perform autograd or backpropagation on the tensor by using the computation graph.\\n\\n\\npytorch is different from numpy as pytorch lets us build tensors which are similar yet different from numpy arays moreover pytorch lets \\nus perform backpropagation and provides both low and high level apis or methods for builidng and training our models.\\n\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Firstly tensor and matrix are very different. Matrix is basically a subset of tensor cuz matrix is 2d while tenors in maths can be \n",
    "1d ( scaler) , 2d , 3d , ... , nd. \n",
    "\n",
    "now for pytorch tensor , it acts like a numpy array but is very different.\n",
    "firstly we can store it on gpu which we cant do with numpy array \n",
    "next they have .grad() property which we can use to calculate their graidents \n",
    "they store compuation graph for the operations performed on the tenosr if we want to stop it \n",
    "from storing computation graph say when maybe we want to validate our model and we dont want the validation calculatioin \n",
    "to hamper the model training computation graph , we can use with torch.no_grad() property. Moreover using \n",
    ".backward() method allows us to perform autograd or backpropagation on the tensor by using the computation graph.\n",
    "\n",
    "\n",
    "pytorch is different from numpy as pytorch lets us build tensors which are similar yet different from numpy arays moreover pytorch lets \n",
    "us perform backpropagation and provides both low and high level apis or methods for builidng and training our models.\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a1383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diff between torch.<method> and torch.<method>_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f05a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "\n",
    "# basically stuff ending with _ is inplace that means they will change the original tensor while the stuff not ending with the _\n",
    "# means it will return a new tensor and wont modify the orignal one \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e546efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7ed54a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2ace90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tensor = torch.tensor([-1 , -2 , 3 ,4 ,5 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba9ffa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b98a5eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 3, 4, 5]) tensor([-1, -2,  3,  4,  5])\n"
     ]
    }
   ],
   "source": [
    "yeah = torch.relu(random_tensor)\n",
    "print(yeah , random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ed007b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 3, 4, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "antoher = torch.relu_(random_tensor)\n",
    "antoher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a28041ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 3, 4, 5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0386975c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllibraries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
