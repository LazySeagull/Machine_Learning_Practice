{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5662095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679ce767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import DataLoader , TensorDataset \n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as T\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b89fb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_type = fetch_covtype(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6676753c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _covtype_dataset:\n",
      "\n",
      "Forest covertypes\n",
      "-----------------\n",
      "\n",
      "The samples in this dataset correspond to 30Ã—30m patches of forest in the US,\n",
      "collected for the task of predicting each patch's cover type,\n",
      "i.e. the dominant species of tree.\n",
      "There are seven covertypes, making this a multiclass classification problem.\n",
      "Each sample has 54 features, described on the\n",
      "`dataset's homepage <https://archive.ics.uci.edu/ml/datasets/Covertype>`__.\n",
      "Some of the features are boolean indicators,\n",
      "while others are discrete or continuous measurements.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "=================   ============\n",
      "Classes                        7\n",
      "Samples total             581012\n",
      "Dimensionality                54\n",
      "Features                     int\n",
      "=================   ============\n",
      "\n",
      ":func:`sklearn.datasets.fetch_covtype` will load the covertype dataset;\n",
      "it returns a dictionary-like 'Bunch' object\n",
      "with the feature matrix in the ``data`` member\n",
      "and the target values in ``target``. If optional argument 'as_frame' is\n",
      "set to 'True', it will return ``data`` and ``target`` as pandas\n",
      "data frame, and there will be an additional member ``frame`` as well.\n",
      "The dataset will be downloaded from the web if necessary.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cov_type.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac3618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_full , x_valid , y_train_full , y_valid = train_test_split(cov_type.data , cov_type.target , random_state=42 , \n",
    "                                                                   test_size=0.15)\n",
    "\n",
    "x_train , x_test , y_train , y_test = train_test_split(x_train_full , y_train_full , random_state=42,\n",
    "                                                       test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "354f4898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cover_Type']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_type.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dc55c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int32(2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bc2732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_valid_scaled = scaler.transform(x_valid)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2085900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f6506e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if y_train.min() >0:\n",
    "    y_test = y_test - 1\n",
    "    y_train = y_train - 1\n",
    "    y_valid = y_valid - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aef6c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(x_train_scaled)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "x_valid = torch.FloatTensor(x_valid_scaled)\n",
    "y_valid = torch.LongTensor(y_valid)\n",
    "x_test = torch.FloatTensor(x_test_scaled)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8fc0a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "print(torch.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d173d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(x_train , y_train)\n",
    "train_loader = DataLoader(train_dataset , shuffle=True , pin_memory=True , batch_size=128 , \n",
    "                          num_workers=4)\n",
    "\n",
    "val_dataset = TensorDataset(x_valid , y_valid)\n",
    "val_loader = DataLoader(val_dataset , shuffle=True , pin_memory=True , batch_size=128 , \n",
    "                          num_workers=4)\n",
    "\n",
    "test_dataset = TensorDataset(x_test , y_test)\n",
    "test_loader = DataLoader(test_dataset , shuffle=True , pin_memory=True , batch_size=128 , \n",
    "                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "499a8e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train and eval function will use device : cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"The train and eval function will use device : {device}\" )\n",
    "\n",
    "\n",
    "def eval(model , val_loader ,metric):\n",
    "    with torch.no_grad():\n",
    "        metric.reset()\n",
    "        model.eval()\n",
    "        for x_val_batch , y_val_batch in val_loader:\n",
    "            x_val_batch , y_val_batch = x_val_batch.to(device) , y_val_batch.to(device)\n",
    "            y_pred_val = model(x_val_batch)\n",
    "            metric.update(y_pred_val , y_val_batch)\n",
    "            \n",
    "    return metric.compute()\n",
    "\n",
    "\n",
    "def train_and_eval(model , train_loader : DataLoader, valid_loader : DataLoader , \n",
    "                   criterion , metric , optimizer) -> dict:\n",
    "    \n",
    "    history = {'train_loss' : [],\n",
    "               'train_accuracy' : [],\n",
    "               'val_accuracy' : []}\n",
    "    \n",
    "\n",
    "    metric.reset()\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for x_batch , y_batch in train_loader:\n",
    "        x_batch , y_batch = x_batch.to(device) , y_batch.to(device)\n",
    "        \n",
    "        #forward\n",
    "        y_pred = model(x_batch)\n",
    "        \n",
    "        #loss\n",
    "        loss = criterion(y_pred , y_batch)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        #optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #back\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        metric.update(y_pred , y_batch)\n",
    "            \n",
    "    mean_loss = total_loss/len(train_loader)\n",
    "    history['train_loss'].append(mean_loss)\n",
    "    \n",
    "    history['train_accuracy'].append(metric.compute().item())\n",
    "    \n",
    "    history['val_accuracy'].append(eval(model , val_loader , metric).item())\n",
    "    \n",
    "    print(f\"Training loss : {history['train_loss'][-1]:.4f}  \",\n",
    "            f\"Training accuracy : {history['train_accuracy'][-1]:.4f}  \",\n",
    "            f\"val accuracy : {history['val_accuracy'][-1]:.4f}\")\n",
    "    \n",
    "    return history\n",
    "        \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e5735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CovTypeClassifier(nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden, n_layers, n_classes, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "\n",
    "        self.hidden_layers.append(nn.Linear(n_inputs, n_hidden))\n",
    "        self.hidden_layers.append(nn.BatchNorm1d(n_hidden))\n",
    "        self.hidden_layers.append(nn.ReLU())\n",
    "        self.hidden_layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        for _ in range(n_layers - 1):\n",
    "            self.hidden_layers.append(nn.Linear(n_hidden, n_hidden))\n",
    "            self.hidden_layers.append(nn.BatchNorm1d(n_hidden))\n",
    "            self.hidden_layers.append(nn.ReLU())\n",
    "            self.hidden_layers.append(nn.Dropout(dropout_rate))\n",
    "\n",
    "        self.output = nn.Linear(n_hidden, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.flatten(1) \n",
    "        \n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "            \n",
    "        return self.output(x)\n",
    "\n",
    "\n",
    "def use_he_init(module):\n",
    "    if isinstance(module , nn.Linear):\n",
    "        nn.init.kaiming_uniform_(module.weight)\n",
    "        nn.init.zeros_(module.bias)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f684e935",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 20\n",
    "\n",
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5 , 1e-1 , log=True)\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 4)\n",
    "    n_hidden = trial.suggest_int(\"n_hidden\" , 20 , 300)\n",
    "    dropout_rate = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    \n",
    "    \n",
    "    model = CovTypeClassifier(n_inputs= 54 , n_hidden=n_hidden , n_layers = n_layers,\n",
    "                               n_classes=7 , dropout_rate = dropout_rate).to(device)\n",
    "    model.apply(use_he_init)\n",
    "    optimizer = torch.optim.Adam(model.parameters() , lr=learning_rate)\n",
    "    accuracy = torchmetrics.Accuracy(task='multiclass' , num_classes=7).to(device)\n",
    "    xentropy = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_score = 0.0\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        history = train_and_eval(model , train_loader , val_loader , xentropy, \n",
    "                                 accuracy , optimizer)\n",
    "        \n",
    "        val_score = max(history['val_accuracy'])\n",
    "        \n",
    "        if val_score > best_val_score:\n",
    "            best_val_score = val_score\n",
    "            \n",
    "        trial.report(val_score , epoch)\n",
    "        \n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "    \n",
    "    return best_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33e6c7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-09 17:10:15,265]\u001b[0m A new study created in memory with name: no-name-a5c8df73-ccb4-48b2-ad10-f56a86250c9e\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss : 1.4293   Training accuracy : 0.4959   val accuracy : 0.5738\n",
      "Training loss : 1.1221   Training accuracy : 0.6005   val accuracy : 0.6218\n",
      "Training loss : 0.9909   Training accuracy : 0.6364   val accuracy : 0.6478\n",
      "Training loss : 0.9162   Training accuracy : 0.6578   val accuracy : 0.6651\n",
      "Training loss : 0.8691   Training accuracy : 0.6706   val accuracy : 0.6743\n",
      "Training loss : 0.8364   Training accuracy : 0.6784   val accuracy : 0.6814\n",
      "Training loss : 0.8118   Training accuracy : 0.6839   val accuracy : 0.6866\n",
      "Training loss : 0.7926   Training accuracy : 0.6889   val accuracy : 0.6920\n",
      "Training loss : 0.7772   Training accuracy : 0.6934   val accuracy : 0.6967\n",
      "Training loss : 0.7645   Training accuracy : 0.6974   val accuracy : 0.7001\n",
      "Training loss : 0.7538   Training accuracy : 0.7006   val accuracy : 0.7037\n",
      "Training loss : 0.7446   Training accuracy : 0.7040   val accuracy : 0.7061\n",
      "Training loss : 0.7365   Training accuracy : 0.7068   val accuracy : 0.7087\n",
      "Training loss : 0.7294   Training accuracy : 0.7090   val accuracy : 0.7111\n",
      "Training loss : 0.7230   Training accuracy : 0.7112   val accuracy : 0.7130\n",
      "Training loss : 0.7172   Training accuracy : 0.7133   val accuracy : 0.7158\n",
      "Training loss : 0.7119   Training accuracy : 0.7153   val accuracy : 0.7172\n",
      "Training loss : 0.7070   Training accuracy : 0.7165   val accuracy : 0.7186\n",
      "Training loss : 0.7025   Training accuracy : 0.7181   val accuracy : 0.7204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-09 17:11:33,388]\u001b[0m Trial 0 finished with value: 0.7217161059379578 and parameters: {'learning_rate': 0.00031489116479568613, 'n_hidden': 287}. Best is trial 0 with value: 0.7217161059379578.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss : 0.6984   Training accuracy : 0.7193   val accuracy : 0.7217\n",
      "Training loss : 0.8457   Training accuracy : 0.6707   val accuracy : 0.7224\n",
      "Training loss : 0.6720   Training accuracy : 0.7272   val accuracy : 0.7350\n",
      "Training loss : 0.6395   Training accuracy : 0.7360   val accuracy : 0.7410\n",
      "Training loss : 0.6195   Training accuracy : 0.7422   val accuracy : 0.7454\n",
      "Training loss : 0.6048   Training accuracy : 0.7465   val accuracy : 0.7481\n",
      "Training loss : 0.5931   Training accuracy : 0.7503   val accuracy : 0.7538\n",
      "Training loss : 0.5830   Training accuracy : 0.7539   val accuracy : 0.7555\n",
      "Training loss : 0.5741   Training accuracy : 0.7570   val accuracy : 0.7594\n",
      "Training loss : 0.5662   Training accuracy : 0.7601   val accuracy : 0.7620\n",
      "Training loss : 0.5589   Training accuracy : 0.7626   val accuracy : 0.7660\n",
      "Training loss : 0.5523   Training accuracy : 0.7654   val accuracy : 0.7677\n",
      "Training loss : 0.5462   Training accuracy : 0.7677   val accuracy : 0.7703\n",
      "Training loss : 0.5404   Training accuracy : 0.7700   val accuracy : 0.7719\n",
      "Training loss : 0.5350   Training accuracy : 0.7723   val accuracy : 0.7750\n",
      "Training loss : 0.5298   Training accuracy : 0.7749   val accuracy : 0.7764\n",
      "Training loss : 0.5250   Training accuracy : 0.7768   val accuracy : 0.7790\n",
      "Training loss : 0.5204   Training accuracy : 0.7789   val accuracy : 0.7807\n",
      "Training loss : 0.5159   Training accuracy : 0.7811   val accuracy : 0.7814\n",
      "Training loss : 0.5118   Training accuracy : 0.7826   val accuracy : 0.7836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-09 17:12:49,228]\u001b[0m Trial 1 finished with value: 0.7840325236320496 and parameters: {'learning_rate': 0.008471801418819975, 'n_hidden': 188}. Best is trial 1 with value: 0.7840325236320496.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss : 0.5077   Training accuracy : 0.7849   val accuracy : 0.7840\n",
      "Training loss : 2.1066   Training accuracy : 0.2381   val accuracy : 0.2749\n",
      "Training loss : 1.9268   Training accuracy : 0.3084   val accuracy : 0.3419\n",
      "Training loss : 1.8053   Training accuracy : 0.3665   val accuracy : 0.3911\n",
      "Training loss : 1.7184   Training accuracy : 0.4077   val accuracy : 0.4238\n",
      "Training loss : 1.6528   Training accuracy : 0.4347   val accuracy : 0.4464\n",
      "Training loss : 1.6008   Training accuracy : 0.4528   val accuracy : 0.4615\n",
      "Training loss : 1.5578   Training accuracy : 0.4659   val accuracy : 0.4726\n",
      "Training loss : 1.5212   Training accuracy : 0.4754   val accuracy : 0.4811\n",
      "Training loss : 1.4892   Training accuracy : 0.4820   val accuracy : 0.4875\n",
      "Training loss : 1.4607   Training accuracy : 0.4879   val accuracy : 0.4927\n",
      "Training loss : 1.4350   Training accuracy : 0.4933   val accuracy : 0.4979\n",
      "Training loss : 1.4115   Training accuracy : 0.4989   val accuracy : 0.5033\n",
      "Training loss : 1.3898   Training accuracy : 0.5043   val accuracy : 0.5091\n",
      "Training loss : 1.3696   Training accuracy : 0.5097   val accuracy : 0.5144\n",
      "Training loss : 1.3508   Training accuracy : 0.5152   val accuracy : 0.5197\n",
      "Training loss : 1.3332   Training accuracy : 0.5205   val accuracy : 0.5247\n",
      "Training loss : 1.3166   Training accuracy : 0.5257   val accuracy : 0.5303\n",
      "Training loss : 1.3009   Training accuracy : 0.5310   val accuracy : 0.5360\n",
      "Training loss : 1.2861   Training accuracy : 0.5364   val accuracy : 0.5415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-09 17:13:58,384]\u001b[0m Trial 2 finished with value: 0.5471245646476746 and parameters: {'learning_rate': 4.207988669606632e-05, 'n_hidden': 63}. Best is trial 1 with value: 0.7840325236320496.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss : 1.2721   Training accuracy : 0.5416   val accuracy : 0.5471\n",
      "Training loss : 1.9642   Training accuracy : 0.2551   val accuracy : 0.2978\n",
      "Training loss : 1.7427   Training accuracy : 0.3345   val accuracy : 0.3622\n",
      "Training loss : 1.6341   Training accuracy : 0.3870   val accuracy : 0.4042\n",
      "Training loss : 1.5684   Training accuracy : 0.4193   val accuracy : 0.4292\n",
      "Training loss : 1.5215   Training accuracy : 0.4391   val accuracy : 0.4445\n",
      "Training loss : 1.4842   Training accuracy : 0.4523   val accuracy : 0.4561\n",
      "Training loss : 1.4525   Training accuracy : 0.4618   val accuracy : 0.4643\n",
      "Training loss : 1.4242   Training accuracy : 0.4694   val accuracy : 0.4713\n",
      "Training loss : 1.3985   Training accuracy : 0.4765   val accuracy : 0.4780\n",
      "Training loss : 1.3746   Training accuracy : 0.4826   val accuracy : 0.4839\n",
      "Training loss : 1.3521   Training accuracy : 0.4886   val accuracy : 0.4896\n",
      "Training loss : 1.3311   Training accuracy : 0.4943   val accuracy : 0.4953\n",
      "Training loss : 1.3112   Training accuracy : 0.5000   val accuracy : 0.5012\n",
      "Training loss : 1.2924   Training accuracy : 0.5056   val accuracy : 0.5067\n",
      "Training loss : 1.2745   Training accuracy : 0.5111   val accuracy : 0.5123\n",
      "Training loss : 1.2575   Training accuracy : 0.5165   val accuracy : 0.5177\n",
      "Training loss : 1.2414   Training accuracy : 0.5219   val accuracy : 0.5228\n",
      "Training loss : 1.2261   Training accuracy : 0.5271   val accuracy : 0.5274\n",
      "Training loss : 1.2115   Training accuracy : 0.5318   val accuracy : 0.5319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-09 17:15:08,202]\u001b[0m Trial 3 finished with value: 0.5367059707641602 and parameters: {'learning_rate': 1.7073967431528103e-05, 'n_hidden': 263}. Best is trial 1 with value: 0.7840325236320496.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss : 1.1976   Training accuracy : 0.5367   val accuracy : 0.5367\n",
      "Training loss : 1.0258   Training accuracy : 0.6070   val accuracy : 0.6713\n",
      "Training loss : 0.7648   Training accuracy : 0.6876   val accuracy : 0.7041\n",
      "Training loss : 0.7092   Training accuracy : 0.7085   val accuracy : 0.7185\n",
      "Training loss : 0.6820   Training accuracy : 0.7191   val accuracy : 0.7256\n",
      "Training loss : 0.6650   Training accuracy : 0.7255   val accuracy : 0.7303\n",
      "Training loss : 0.6528   Training accuracy : 0.7301   val accuracy : 0.7351\n",
      "Training loss : 0.6432   Training accuracy : 0.7335   val accuracy : 0.7375\n",
      "Training loss : 0.6350   Training accuracy : 0.7366   val accuracy : 0.7402\n",
      "Training loss : 0.6279   Training accuracy : 0.7392   val accuracy : 0.7420\n",
      "Training loss : 0.6215   Training accuracy : 0.7417   val accuracy : 0.7440\n",
      "Training loss : 0.6158   Training accuracy : 0.7438   val accuracy : 0.7466\n",
      "Training loss : 0.6104   Training accuracy : 0.7457   val accuracy : 0.7480\n",
      "Training loss : 0.6055   Training accuracy : 0.7476   val accuracy : 0.7500\n",
      "Training loss : 0.6009   Training accuracy : 0.7493   val accuracy : 0.7513\n",
      "Training loss : 0.5966   Training accuracy : 0.7509   val accuracy : 0.7524\n",
      "Training loss : 0.5924   Training accuracy : 0.7524   val accuracy : 0.7543\n",
      "Training loss : 0.5885   Training accuracy : 0.7539   val accuracy : 0.7558\n",
      "Training loss : 0.5848   Training accuracy : 0.7554   val accuracy : 0.7574\n",
      "Training loss : 0.5814   Training accuracy : 0.7568   val accuracy : 0.7582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-02-09 17:16:29,245]\u001b[0m Trial 4 finished with value: 0.7599940299987793 and parameters: {'learning_rate': 0.002537815508265664, 'n_hidden': 218}. Best is trial 1 with value: 0.7840325236320496.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss : 0.5780   Training accuracy : 0.7580   val accuracy : 0.7600\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "study = optuna.create_study(direction='maximize' , sampler=sampler)\n",
    "study.optimize(objective , n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ed26a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_best , n_hidden_best = study.best_params['learning_rate'] , study.best_params['n_hidden']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6d1eb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008471801418819975 188\n"
     ]
    }
   ],
   "source": [
    "print(learning_rate_best , n_hidden_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d3beed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss : 0.8321   Training accuracy : 0.6777   val accuracy : 0.7161\n",
      "Training loss : 0.6783   Training accuracy : 0.7228   val accuracy : 0.7324\n",
      "Training loss : 0.6441   Training accuracy : 0.7342   val accuracy : 0.7405\n",
      "Training loss : 0.6233   Training accuracy : 0.7408   val accuracy : 0.7452\n",
      "Training loss : 0.6078   Training accuracy : 0.7461   val accuracy : 0.7494\n",
      "Training loss : 0.5954   Training accuracy : 0.7502   val accuracy : 0.7532\n",
      "Training loss : 0.5848   Training accuracy : 0.7538   val accuracy : 0.7581\n",
      "Training loss : 0.5753   Training accuracy : 0.7573   val accuracy : 0.7607\n",
      "Training loss : 0.5669   Training accuracy : 0.7608   val accuracy : 0.7641\n",
      "Training loss : 0.5592   Training accuracy : 0.7642   val accuracy : 0.7669\n",
      "Training loss : 0.5522   Training accuracy : 0.7674   val accuracy : 0.7708\n",
      "Training loss : 0.5458   Training accuracy : 0.7701   val accuracy : 0.7734\n",
      "Training loss : 0.5399   Training accuracy : 0.7730   val accuracy : 0.7729\n",
      "Training loss : 0.5342   Training accuracy : 0.7755   val accuracy : 0.7773\n",
      "Training loss : 0.5290   Training accuracy : 0.7776   val accuracy : 0.7791\n",
      "Training loss : 0.5241   Training accuracy : 0.7794   val accuracy : 0.7810\n",
      "Training loss : 0.5193   Training accuracy : 0.7814   val accuracy : 0.7837\n",
      "Training loss : 0.5148   Training accuracy : 0.7831   val accuracy : 0.7854\n",
      "Training loss : 0.5104   Training accuracy : 0.7850   val accuracy : 0.7868\n",
      "Training loss : 0.5063   Training accuracy : 0.7861   val accuracy : 0.7878\n"
     ]
    }
   ],
   "source": [
    "model = CovTypeClassifier(n_inputs=54 , n_hidden1=n_hidden_best , \n",
    "                          n_hidden2= n_hidden_best , n_classes=7).to(device)\n",
    "\n",
    "model.apply(use_he_init)\n",
    "optimizer = torch.optim.SGD(model.parameters() , lr=learning_rate_best)\n",
    "accuracy = torchmetrics.Accuracy(task='multiclass' , num_classes=7).to(device)\n",
    "xentropy = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    history_best = train_and_eval(model , train_loader , val_loader , xentropy, \n",
    "                                 accuracy , optimizer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700320e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllibraries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
